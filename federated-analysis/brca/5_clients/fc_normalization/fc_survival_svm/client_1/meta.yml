model:
  coefficients:
    intercept: 8.136937433853907
    weights:
      X200726_at: 0.0009468413020371928
      X200965_s_at: 0.001485022298827742
      X201068_s_at: -0.000724068334588986
      X201091_s_at: -0.0016052717159241714
      X201288_at: 0.0025311493183956648
      X201368_at: 0.0017839666325749884
      X201663_s_at: -0.002118979971914932
      X201664_at: -0.0020104646667206375
      X202239_at: 0.0023775649235337443
      X202240_at: -0.0029966181575303277
      X202418_at: -0.0013859208026583989
      X202687_s_at: 0.0016954714565860932
      X203306_s_at: 0.002290471801118177
      X203391_at: 0.0027376187394070675
      X204014_at: 0.002884509496380601
      X204015_s_at: 0.0018618579944223266
      X204073_s_at: -0.00010376154693846053
      X204218_at: 0.00035128433036623626
      X204540_at: -0.001271468886917033
      X204631_at: 0.0003443922280253382
      X204740_at: 0.0017412563982627022
      X204768_s_at: -0.0013621623972748563
      X204888_s_at: -0.00040325852687874705
      X205034_at: -0.001956185115042695
      X205848_at: -3.8413896100019484e-05
      X206295_at: 0.0014174558663904663
      X207118_s_at: -0.0015709118578056294
      X208180_s_at: -0.0017938909140950794
      X208683_at: 0.0005500842637868545
      X209500_x_at: -0.0006527451764503153
      X209524_at: -0.0003871922535681296
      X209835_x_at: -0.0008986817336251124
      X209862_s_at: -0.000677389370074664
      X210028_s_at: -2.9066054691494845e-05
      X210314_x_at: -0.00048134793782345553
      X210593_at: 7.898626076398383e-05
      X211040_x_at: -0.001713293589368821
      X211382_s_at: 0.0013155449367103901
      X211762_s_at: -0.0013185516756649277
      X211779_x_at: 0.0023406623240251182
      X212014_x_at: -0.001537757523089011
      X212567_s_at: -9.527886718265112e-05
      X214806_at: -0.0012875255051041582
      X214915_at: -0.0010060971064818072
      X214919_s_at: 0.0016614792972307877
      X215510_at: 0.00035360294659920116
      X215633_x_at: 0.0010686486990119622
      X216010_x_at: 0.0003572169311263511
      X216103_at: 0.0008795698319018298
      X216693_x_at: -0.00023360699613279048
      X217019_at: 0.0005312617225372094
      X217102_at: -0.00014502041495922274
      X217404_s_at: -0.0006649996565266785
      X217471_at: -0.0006432578580956842
      X217767_at: 0.000745761066838563
      X217771_at: 0.0011091087157187578
      X217815_at: -0.0001574093947034302
      X218430_s_at: 0.0005278887350684535
      X218478_s_at: 0.0015455962412695514
      X218533_s_at: -0.0004980764942628733
      X218782_s_at: -0.0015552794735326707
      X218883_s_at: -0.004197896938631867
      X218914_at: -0.0001263340751058516
      X219340_s_at: 0.0014389861707238653
      X219510_at: -0.0012353559284966967
      X219588_s_at: -0.000707001602678304
      X219724_s_at: 0.0017957711012247604
      X220886_at: -0.0012868496834423171
      X221028_s_at: -0.0014642901347454577
      X221241_s_at: 0.0006422577737071098
      X221344_at: 7.109547251717901e-05
      X221634_at: -0.0004036313216323189
      X221816_s_at: 0.000906309182902472
      X221882_s_at: -0.0006425461151785312
      X221916_at: 0.002731811221483186
      X221928_at: 0.0021657224682301093
      age: 0.0002858559610784503
      er_positive: 0.003495612165284754
      grade_intermediate: 0.0015695570199989667
      grade_poorly differentiated: -0.0026030361300075915
      grade_unkown: 0.0008180476330474937
      size: -0.002497467947678247
  name: FederatedPureRegressionSurvivalSVM
  optimizer:
    fun: 0.005529733415971946
    jac:
    - -4.637254335138497e-10
    - -8.641092365735056e-09
    - 1.747112342341886e-08
    - -1.6341445071904256e-08
    - -1.6107578021612792e-08
    - 1.533333646207627e-08
    - 2.9407647054915248e-08
    - -1.7490586694257626e-08
    - -1.0141391891625023e-08
    - -1.30210523530995e-08
    - -2.4195283437368487e-08
    - -1.720660270342067e-08
    - 6.6039893052791815e-09
    - -1.4351227818967804e-09
    - 2.2948223340254342e-08
    - 2.955134536641174e-08
    - 4.390858788258338e-08
    - -2.3959241868875343e-08
    - 2.422268530611997e-09
    - 1.7061183753101783e-08
    - -1.4392955182285921e-08
    - 7.003555258953617e-09
    - -3.75811855936152e-08
    - -1.1461219060404301e-09
    - -2.4950166592485612e-08
    - -2.854895619726545e-09
    - 2.5034267412977346e-09
    - 1.0585008606168317e-08
    - -8.749742838685265e-09
    - 5.988836514702299e-09
    - 2.2257289811005408e-08
    - 1.0720214250374907e-08
    - -1.3616340950161482e-08
    - -9.509394759805133e-09
    - -2.040744463029093e-08
    - 2.8944769133701538e-08
    - 7.512737586467264e-09
    - -3.955412487236139e-08
    - -5.283447387059714e-09
    - -4.24500718979471e-08
    - -2.256836620362357e-09
    - -7.511263329417275e-09
    - 4.051095903152098e-09
    - 1.1585293652801448e-08
    - -1.0371659967499391e-09
    - 1.6579675087479914e-08
    - 8.361247744517741e-09
    - 1.694946686909421e-09
    - 4.098219192933024e-10
    - 3.909404129413818e-09
    - 6.133202834951489e-09
    - 5.0988975429031025e-09
    - 1.768074764396145e-09
    - -1.12238642462157e-08
    - 3.130380570102835e-09
    - 3.418724223202066e-08
    - 2.5313183580266338e-08
    - -1.0992938037965696e-08
    - 1.733714027397394e-08
    - -1.047413940020829e-08
    - -1.7194008762448122e-08
    - -2.563060128892014e-08
    - -9.859036054563064e-09
    - 7.880811937603129e-09
    - 1.292937909730743e-09
    - -2.256627836439047e-08
    - -4.510979980678308e-08
    - -4.158473656352621e-09
    - -3.9310761590360954e-09
    - -7.472221218943892e-09
    - -1.5764055047223433e-09
    - 2.6778729212112006e-09
    - -9.565082226324715e-09
    - 1.5954548281474357e-08
    - -7.829709432563038e-09
    - -4.639931271230996e-09
    - 1.0708359367631037e-08
    - 1.318990599369612e-08
    - -1.8557244937759954e-09
    - 4.399958696867101e-09
    - 7.958463602974336e-09
    - -1.72606655257819e-08
    - -3.761991994614619e-09
    message: Optimization terminated successfully.
    nfev: 5
    nhev: 10
    nit: 4
    njev: 5
    status: 0
    success: true
    x:
    - 8.136937433853907
    - 0.0009468413020371928
    - 0.001485022298827742
    - -0.000724068334588986
    - -0.0016052717159241714
    - 0.0025311493183956648
    - 0.0017839666325749884
    - -0.002118979971914932
    - -0.0020104646667206375
    - 0.0023775649235337443
    - -0.0029966181575303277
    - -0.0013859208026583989
    - 0.0016954714565860932
    - 0.002290471801118177
    - 0.0027376187394070675
    - 0.002884509496380601
    - 0.0018618579944223266
    - -0.00010376154693846053
    - 0.00035128433036623626
    - -0.001271468886917033
    - 0.0003443922280253382
    - 0.0017412563982627022
    - -0.0013621623972748563
    - -0.00040325852687874705
    - -0.001956185115042695
    - -3.8413896100019484e-05
    - 0.0014174558663904663
    - -0.0015709118578056294
    - -0.0017938909140950794
    - 0.0005500842637868545
    - -0.0006527451764503153
    - -0.0003871922535681296
    - -0.0008986817336251124
    - -0.000677389370074664
    - -2.9066054691494845e-05
    - -0.00048134793782345553
    - 7.898626076398383e-05
    - -0.001713293589368821
    - 0.0013155449367103901
    - -0.0013185516756649277
    - 0.0023406623240251182
    - -0.001537757523089011
    - -9.527886718265112e-05
    - -0.0012875255051041582
    - -0.0010060971064818072
    - 0.0016614792972307877
    - 0.00035360294659920116
    - 0.0010686486990119622
    - 0.0003572169311263511
    - 0.0008795698319018298
    - -0.00023360699613279048
    - 0.0005312617225372094
    - -0.00014502041495922274
    - -0.0006649996565266785
    - -0.0006432578580956842
    - 0.000745761066838563
    - 0.0011091087157187578
    - -0.0001574093947034302
    - 0.0005278887350684535
    - 0.0015455962412695514
    - -0.0004980764942628733
    - -0.0015552794735326707
    - -0.004197896938631867
    - -0.0001263340751058516
    - 0.0014389861707238653
    - -0.0012353559284966967
    - -0.000707001602678304
    - 0.0017957711012247604
    - -0.0012868496834423171
    - -0.0014642901347454577
    - 0.0006422577737071098
    - 7.109547251717901e-05
    - -0.0004036313216323189
    - 0.000906309182902472
    - -0.0006425461151785312
    - 0.002731811221483186
    - 0.0021657224682301093
    - 0.0002858559610784503
    - -0.002497467947678247
    - 0.003495612165284754
    - 0.0015695570199989667
    - -0.0026030361300075915
    - 0.0008180476330474937
  privacy:
    privacy_technique: None
  timings:
    config: 3.0226182930018695
    generate_predictions: 0.07254191700121737
    optimizer:
      calculation_time: 0.006482123993919231
      idle_time: 95.60846016900541
      total_time: 95.61494229299933
    preprocessing: 0.0003709170014190022
    read_data: 0.06446033300017007
    total_until_meta_file_write: 133.57584793500064
  training_data:
    event_censored_value: '0'
    event_value: '1'
    label_event: event
    label_survival_time: tte
    local_file: OVERALL/train_norm.csv
    n_censored: 147
    n_samples: 198
    split: OVERALL
  training_parameters:
    alpha: 0.0001
    fit_intercept: true
    max_iter: 50
    rank_ratio: 0
  version: v1.0.0-alpha
